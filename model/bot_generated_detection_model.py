# -*- coding: utf-8 -*-
"""Bot_Generated_Detection_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cNWZPCXVVAeHzUGeQnEupxKtpD1Ci10O

Import file
"""

#from google.colab import files
#uploaded = files.upload()

"""Load your dataset"""

#import pandas as pd
#import io
#df = pd.read_excel(io.BytesIO(uploaded['fake reviews dataset (new).xlsx']))
import pandas as pd

file_path = "data\\fake reviews dataset (new).xlsx"
df = pd.read_excel(file_path)



"""Import libraries"""

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

nltk.download('stopwords')

"""Text preprocessing"""

stop_words = set(stopwords.words('english'))

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-z\s]', '', text)  # remove punctuation/numbers
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return ' '.join(tokens)

df['clean_text'] = df['text_'].apply(clean_text)

"""Feature engineering"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import hstack

# Step 1: Review length
df['review_length'] = df['clean_text'].apply(lambda x: len(x.split()))

# Step 2: TF-IDF
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(df['clean_text'])

# Step 3: Combine TF-IDF with other numerical features
# Select all category_* columns + review_length
X_other = df[['review_length', 'rating']].astype(float).values

# Step 4: Combine sparse + dense
X = hstack([X_tfidf, X_other])

# Step 5: Target
y = df['label'].values

print(df.columns)

"""Train/test split"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

"""Build detection model"""

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:,1]

"""Evaluate model"""

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("ROC-AUC Score:", roc_auc_score(y_test, y_prob))

"""Bot-Generated Review Detection"""

new_review = {
    'text_': "This product is amazing! Iâ€™ve never seen anything like it before. Highly recommend to everyone.",
    'rating': 2
}

new_df = pd.DataFrame([new_review])

# Clean the text
new_df['clean_text'] = new_df['text_'].apply(clean_text)

# Review length
new_df['review_length'] = new_df['clean_text'].apply(lambda x: len(x.split()))

X_tfidf_new = tfidf.transform(new_df['clean_text'])

X_other_new = new_df[['review_length', 'rating']].astype(float).values
from scipy.sparse import hstack
X_new = hstack([tfidf.transform(new_df['clean_text']),X_other_new])

pred_label = model.predict(X_new)[0]
pred_prob = model.predict_proba(X_new)[0][0]

print("Detection:", pred_label)
print("Probability (bot-generated):", pred_prob)

"""Test"""

new_reviews = [
    {'text_': "Great value. Delivered quickly. Would buy again.", 'rating': 5},
    {'text_': "Best product I've ever used!!! Highly recommend!!!", 'rating': 4},
]

# Convert to DataFrame
new_df = pd.DataFrame(new_reviews)

# Clean the text
new_df['clean_text'] = new_df['text_'].apply(clean_text)

# Review length
new_df['review_length'] = new_df['clean_text'].apply(lambda x: len(x.split()))


# TF-IDF
X_tfidf_new = tfidf.transform(new_df['clean_text'])

# Combine features
X_other_new = new_df[['review_length', 'rating']].astype(float).values
X_new = hstack([X_tfidf_new, X_other_new])

# Predict
pred_labels = model.predict(X_new)
pred_probs = model.predict_proba(X_new)[:, 0]  # Probability of CG (bot-generated)

# Show results
for i, review in enumerate(new_df['text_']):
    print(f"Review {i+1}:")
    print("Text:", review)
    print("Detection:", pred_labels[i])
    print(f"Probability of bot-generated (CG): {pred_probs[i]:.4f}")
    print("---")



#Save model
import joblib
joblib.dump(tfidf, 'model/bgdm_tfidf_vectorizer.pkl')
joblib.dump(model, 'model/Bot_Generated_Detection_Model.pkl')