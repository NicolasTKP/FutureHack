# Lazada Veracity Checker
This project builds and trains a machine learning model to detect bot-generated (computer-generated) product reviews using Natural Language Processing (NLP) techniques.
## Project Overview
The goal is to help e-commerce platforms identify fake reviews that could mislead customers. The model analyzes the content of a review, like review length and rating, to predict whether the review is likely generated by a bot.
## Dataset
- **File:** `fake reviews dataset (new).xlsx`
- **Columns Used:**
  - `text_`: the review text
  - `rating`: numerical rating given by the user
  - `label`: binary target 
## Model Details
- **Preprocessing:**
  - Lowercasing
  - Removal of punctuation/numbers
  - Stopword removal using NLTK
- **Features:**
  - TF-IDF vectorized review text (max 5000 features)
  - Review length (word count)
  - Rating (1â€“5 scale)
- **Model Used:** Logistic Regression
- **Evaluation Metrics:**
  - Confusion Matrix
  - Classification Report (Precision, Recall, F1)
  - ROC-AUC Score
- **Review and Rating Sentiment Matching Model**
  This project uses LinearSVC model to 
    - Analyse the text sentiment of a product review
    - Compare the result with the given rating
    - Flag inconsistencies (difference between predicted rating and given rating >=2)
## Rule-Based Malicious Word Detection
 This project includes a rule-based module and a utility function to 
   - Detect and flag reviews that contain malicious or rude keywords
   - Identify toxic words in both English and Malay
## Performance
```
Classification Report:
               precision    recall  f1-score   support

          CG       0.88      0.86      0.87      4044
          OR       0.87      0.88      0.88      4043

    accuracy                           0.87      8087
   macro avg       0.87      0.87      0.87      8087
weighted avg       0.87      0.87      0.87      8087

Confusion Matrix:
 [[3492  552]
 [ 469 3574]]
ROC-AUC Score: 0.9460312031418922
```
- **LinearSVC model (Review and Rating Sentiment Matching Model)**
```
Classification Report:
               precision    recall  f1-score   support

    negative       0.82      0.80      0.81     45528
    positive       0.80      0.82      0.81     45528

    accuracy                           0.81     91056
   macro avg       0.81      0.81      0.81     91056
weighted avg       0.81      0.81      0.81     91056

Confusion Matrix:
 [[36320  9208]
 [ 7991 37537]]
```
## Installation
**Install the following python dependency**

```python
pip install requirements.txt
```
